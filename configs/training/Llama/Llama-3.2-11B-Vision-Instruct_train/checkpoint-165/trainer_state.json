{
  "best_metric": 0.05145354,
  "best_model_checkpoint": "/ws/Anomaly_Det_VLM/configs/training/Llama/Llama-3.2-11B-Vision-Instruct_train/checkpoint-150",
  "epoch": 4.865671641791045,
  "eval_steps": 50,
  "global_step": 165,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.029850746268656716,
      "grad_norm": 13.903097152709961,
      "learning_rate": 1.1111111111111112e-05,
      "loss": 4.106904029846191,
      "memory(GiB)": 50.09,
      "step": 1,
      "token_acc": 0.4247787610619469,
      "train_speed(iter/s)": 0.019832
    },
    {
      "epoch": 0.14925373134328357,
      "grad_norm": 28.569231033325195,
      "learning_rate": 5.555555555555556e-05,
      "loss": 3.1146240234375,
      "memory(GiB)": 50.22,
      "step": 5,
      "token_acc": 0.475,
      "train_speed(iter/s)": 0.024664
    },
    {
      "epoch": 0.29850746268656714,
      "grad_norm": 4.125044345855713,
      "learning_rate": 9.998986144924251e-05,
      "loss": 1.1110963821411133,
      "memory(GiB)": 50.22,
      "step": 10,
      "token_acc": 0.7357414448669202,
      "train_speed(iter/s)": 0.025477
    },
    {
      "epoch": 0.44776119402985076,
      "grad_norm": 9.31667423248291,
      "learning_rate": 9.96354437049027e-05,
      "loss": 0.6148659706115722,
      "memory(GiB)": 50.22,
      "step": 15,
      "token_acc": 0.8171521035598706,
      "train_speed(iter/s)": 0.025792
    },
    {
      "epoch": 0.5970149253731343,
      "grad_norm": 3.411224126815796,
      "learning_rate": 9.877820254235471e-05,
      "loss": 0.3869162082672119,
      "memory(GiB)": 50.22,
      "step": 20,
      "token_acc": 0.8763326226012793,
      "train_speed(iter/s)": 0.025935
    },
    {
      "epoch": 0.746268656716418,
      "grad_norm": 5.868239402770996,
      "learning_rate": 9.742682209735727e-05,
      "loss": 0.28912944793701173,
      "memory(GiB)": 50.22,
      "step": 25,
      "token_acc": 0.8837719298245614,
      "train_speed(iter/s)": 0.026018
    },
    {
      "epoch": 0.8955223880597015,
      "grad_norm": 3.37959623336792,
      "learning_rate": 9.559499229960451e-05,
      "loss": 0.30322632789611814,
      "memory(GiB)": 50.22,
      "step": 30,
      "token_acc": 0.9094076655052264,
      "train_speed(iter/s)": 0.026073
    },
    {
      "epoch": 1.0298507462686568,
      "grad_norm": 1.4498445987701416,
      "learning_rate": 9.330127018922194e-05,
      "loss": 0.17386142015457154,
      "memory(GiB)": 50.22,
      "step": 35,
      "token_acc": 0.926530612244898,
      "train_speed(iter/s)": 0.02645
    },
    {
      "epoch": 1.1791044776119404,
      "grad_norm": 1.266594409942627,
      "learning_rate": 9.056889192782866e-05,
      "loss": 0.19044758081436158,
      "memory(GiB)": 50.22,
      "step": 40,
      "token_acc": 0.931095406360424,
      "train_speed(iter/s)": 0.026397
    },
    {
      "epoch": 1.328358208955224,
      "grad_norm": 0.9078402519226074,
      "learning_rate": 8.742553740855506e-05,
      "loss": 0.12855982780456543,
      "memory(GiB)": 50.22,
      "step": 45,
      "token_acc": 0.954468802698145,
      "train_speed(iter/s)": 0.026357
    },
    {
      "epoch": 1.4776119402985075,
      "grad_norm": 7.812080383300781,
      "learning_rate": 8.390304984959454e-05,
      "loss": 0.14849826097488403,
      "memory(GiB)": 50.22,
      "step": 50,
      "token_acc": 0.9588014981273408,
      "train_speed(iter/s)": 0.026324
    },
    {
      "epoch": 1.4776119402985075,
      "eval_loss": 0.2905465066432953,
      "eval_runtime": 82.738,
      "eval_samples_per_second": 0.713,
      "eval_steps_per_second": 0.713,
      "step": 50
    },
    {
      "epoch": 1.626865671641791,
      "grad_norm": 0.9895626306533813,
      "learning_rate": 8.003711321189895e-05,
      "loss": 0.11054937839508057,
      "memory(GiB)": 50.22,
      "step": 55,
      "token_acc": 0.9558676028084253,
      "train_speed(iter/s)": 0.025279
    },
    {
      "epoch": 1.7761194029850746,
      "grad_norm": 1.7135263681411743,
      "learning_rate": 7.586689070888284e-05,
      "loss": 0.10817700624465942,
      "memory(GiB)": 50.22,
      "step": 60,
      "token_acc": 0.9585585585585585,
      "train_speed(iter/s)": 0.025343
    },
    {
      "epoch": 1.9253731343283582,
      "grad_norm": 0.7804045081138611,
      "learning_rate": 7.143462807015271e-05,
      "loss": 0.06796079874038696,
      "memory(GiB)": 50.22,
      "step": 65,
      "token_acc": 0.9784313725490196,
      "train_speed(iter/s)": 0.025391
    },
    {
      "epoch": 2.0597014925373136,
      "grad_norm": 2.2179086208343506,
      "learning_rate": 6.678522557833024e-05,
      "loss": 0.05906956791877747,
      "memory(GiB)": 50.22,
      "step": 70,
      "token_acc": 0.9747368421052631,
      "train_speed(iter/s)": 0.025602
    },
    {
      "epoch": 2.208955223880597,
      "grad_norm": 0.32814234495162964,
      "learning_rate": 6.19657832143779e-05,
      "loss": 0.03918816745281219,
      "memory(GiB)": 50.22,
      "step": 75,
      "token_acc": 0.9890310786106032,
      "train_speed(iter/s)": 0.025641
    },
    {
      "epoch": 2.3582089552238807,
      "grad_norm": 2.399380922317505,
      "learning_rate": 5.702512351925464e-05,
      "loss": 0.06447346210479736,
      "memory(GiB)": 50.22,
      "step": 80,
      "token_acc": 0.9794520547945206,
      "train_speed(iter/s)": 0.025681
    },
    {
      "epoch": 2.5074626865671643,
      "grad_norm": 1.082184076309204,
      "learning_rate": 5.201329700547076e-05,
      "loss": 0.06279917955398559,
      "memory(GiB)": 50.22,
      "step": 85,
      "token_acc": 0.9781021897810219,
      "train_speed(iter/s)": 0.025712
    },
    {
      "epoch": 2.656716417910448,
      "grad_norm": 0.5461616516113281,
      "learning_rate": 4.6981075128885693e-05,
      "loss": 0.03853805363178253,
      "memory(GiB)": 50.22,
      "step": 90,
      "token_acc": 0.9860279441117764,
      "train_speed(iter/s)": 0.025741
    },
    {
      "epoch": 2.8059701492537314,
      "grad_norm": 0.6590846180915833,
      "learning_rate": 4.197943595711198e-05,
      "loss": 0.046141991019248964,
      "memory(GiB)": 50.22,
      "step": 95,
      "token_acc": 0.9826254826254827,
      "train_speed(iter/s)": 0.025766
    },
    {
      "epoch": 2.955223880597015,
      "grad_norm": 0.8603881001472473,
      "learning_rate": 3.705904774487396e-05,
      "loss": 0.04153882563114166,
      "memory(GiB)": 50.22,
      "step": 100,
      "token_acc": 0.9876760563380281,
      "train_speed(iter/s)": 0.025789
    },
    {
      "epoch": 2.955223880597015,
      "eval_loss": 0.0555596761405468,
      "eval_runtime": 82.7575,
      "eval_samples_per_second": 0.713,
      "eval_steps_per_second": 0.713,
      "step": 100
    },
    {
      "epoch": 3.08955223880597,
      "grad_norm": 0.7542209625244141,
      "learning_rate": 3.226975564787322e-05,
      "loss": 0.012713991105556488,
      "memory(GiB)": 50.22,
      "step": 105,
      "token_acc": 0.9902491874322861,
      "train_speed(iter/s)": 0.025393
    },
    {
      "epoch": 3.2388059701492535,
      "grad_norm": 1.5988588333129883,
      "learning_rate": 2.7660076774918708e-05,
      "loss": 0.034649434685707095,
      "memory(GiB)": 50.22,
      "step": 110,
      "token_acc": 0.9919191919191919,
      "train_speed(iter/s)": 0.025422
    },
    {
      "epoch": 3.388059701492537,
      "grad_norm": 2.2748308181762695,
      "learning_rate": 2.3276708693609943e-05,
      "loss": 0.03126018941402435,
      "memory(GiB)": 50.22,
      "step": 115,
      "token_acc": 0.9900990099009901,
      "train_speed(iter/s)": 0.025454
    },
    {
      "epoch": 3.5373134328358207,
      "grad_norm": 2.035543918609619,
      "learning_rate": 1.9164056368572846e-05,
      "loss": 0.03191775381565094,
      "memory(GiB)": 50.22,
      "step": 120,
      "token_acc": 0.9883720930232558,
      "train_speed(iter/s)": 0.025483
    },
    {
      "epoch": 3.6865671641791042,
      "grad_norm": 2.012925148010254,
      "learning_rate": 1.536378232452003e-05,
      "loss": 0.018279415369033814,
      "memory(GiB)": 50.22,
      "step": 125,
      "token_acc": 0.9937888198757764,
      "train_speed(iter/s)": 0.02551
    },
    {
      "epoch": 3.835820895522388,
      "grad_norm": 0.18266244232654572,
      "learning_rate": 1.1914384591132044e-05,
      "loss": 0.016948021948337555,
      "memory(GiB)": 50.22,
      "step": 130,
      "token_acc": 0.9920760697305864,
      "train_speed(iter/s)": 0.025536
    },
    {
      "epoch": 3.9850746268656714,
      "grad_norm": 0.8379815816879272,
      "learning_rate": 8.850806705317183e-06,
      "loss": 0.015595163404941558,
      "memory(GiB)": 50.22,
      "step": 135,
      "token_acc": 0.993103448275862,
      "train_speed(iter/s)": 0.025559
    },
    {
      "epoch": 4.119402985074627,
      "grad_norm": 1.000182032585144,
      "learning_rate": 6.204083721655607e-06,
      "loss": 0.026201131939888,
      "memory(GiB)": 50.22,
      "step": 140,
      "token_acc": 0.9939024390243902,
      "train_speed(iter/s)": 0.025665
    },
    {
      "epoch": 4.268656716417911,
      "grad_norm": 0.09445994347333908,
      "learning_rate": 4.001027817058789e-06,
      "loss": 0.014585168659687042,
      "memory(GiB)": 50.22,
      "step": 145,
      "token_acc": 0.9930555555555556,
      "train_speed(iter/s)": 0.025687
    },
    {
      "epoch": 4.417910447761194,
      "grad_norm": 1.1122890710830688,
      "learning_rate": 2.2639566745727205e-06,
      "loss": 0.01045629009604454,
      "memory(GiB)": 50.22,
      "step": 150,
      "token_acc": 0.9963570127504554,
      "train_speed(iter/s)": 0.025705
    },
    {
      "epoch": 4.417910447761194,
      "eval_loss": 0.051453541964292526,
      "eval_runtime": 82.1296,
      "eval_samples_per_second": 0.718,
      "eval_steps_per_second": 0.718,
      "step": 150
    },
    {
      "epoch": 4.567164179104478,
      "grad_norm": 0.1266782134771347,
      "learning_rate": 1.0104673978866164e-06,
      "loss": 0.011892847716808319,
      "memory(GiB)": 50.22,
      "step": 155,
      "token_acc": 0.99000999000999,
      "train_speed(iter/s)": 0.025373
    },
    {
      "epoch": 4.7164179104477615,
      "grad_norm": 0.11590604484081268,
      "learning_rate": 2.532582468677214e-07,
      "loss": 0.02049580216407776,
      "memory(GiB)": 50.22,
      "step": 160,
      "token_acc": 0.994328922495274,
      "train_speed(iter/s)": 0.0254
    },
    {
      "epoch": 4.865671641791045,
      "grad_norm": 0.23483061790466309,
      "learning_rate": 0.0,
      "loss": 0.003615092486143112,
      "memory(GiB)": 50.22,
      "step": 165,
      "token_acc": 1.0,
      "train_speed(iter/s)": 0.025427
    },
    {
      "epoch": 4.865671641791045,
      "eval_loss": 0.05223697051405907,
      "eval_runtime": 82.8058,
      "eval_samples_per_second": 0.713,
      "eval_steps_per_second": 0.713,
      "step": 165
    }
  ],
  "logging_steps": 5,
  "max_steps": 165,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.6064522832224184e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
